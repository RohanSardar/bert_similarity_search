{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-24T09:37:07.205402Z",
     "iopub.status.busy": "2025-12-24T09:37:07.202302Z",
     "iopub.status.idle": "2025-12-24T09:37:33.755491Z",
     "shell.execute_reply": "2025-12-24T09:37:33.754820Z",
     "shell.execute_reply.started": "2025-12-24T09:37:07.205371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Define BERTSimilarity Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:37:33.757438Z",
     "iopub.status.busy": "2025-12-24T09:37:33.756846Z",
     "iopub.status.idle": "2025-12-24T09:37:33.766089Z",
     "shell.execute_reply": "2025-12-24T09:37:33.765509Z",
     "shell.execute_reply.started": "2025-12-24T09:37:33.757411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BERTSimilarity:\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", vocab_size=30522, batch_size=256):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.model = BertModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        raw_vocab = list(self.tokenizer.get_vocab().keys())\n",
    "        self.vocab = self._filter_vocab(raw_vocab)[:vocab_size]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.token_embeddings = self._compute_vocab_embeddings()\n",
    "\n",
    "    def _filter_vocab(self, vocab):\n",
    "        \"\"\"\n",
    "        Removes special tokens, subwords, non-alphabetic tokens, short words.\n",
    "        \"\"\"\n",
    "        filtered = [\n",
    "            token for token in vocab\n",
    "            if token.isalpha() and not token.startswith(\"##\") and len(token) > 2\n",
    "        ]\n",
    "        return filtered\n",
    "\n",
    "    def _compute_vocab_embeddings(self):\n",
    "        \"\"\"\n",
    "        Compute embeddings for filtered vocab using batching.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(self.vocab), self.batch_size), desc=\"Computing embeddings\"):\n",
    "            batch_tokens = self.vocab[i:i+self.batch_size]\n",
    "            inputs = self.tokenizer(batch_tokens, return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                batch_embeds = outputs.last_hidden_state.mean(dim=1)\n",
    "                embeddings.append(batch_embeds)\n",
    "\n",
    "        return torch.cat(embeddings, dim=0)\n",
    "\n",
    "    def get_similar_words(self, input_word, top_n=10):\n",
    "        \"\"\"\n",
    "        Given an input word, return top N similar words.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(input_word, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            input_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        similarities = F.cosine_similarity(input_embedding, self.token_embeddings, dim=1)\n",
    "        top_indices = torch.topk(similarities, top_n).indices\n",
    "        similar_words = [(self.vocab[i], float(similarities[i])) for i in top_indices]\n",
    "        return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cb51f6e34748b889aa2a2da8bba1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded & embeddings computed...\n"
     ]
    }
   ],
   "source": [
    "bert_model = BERTSimilarity(vocab_size=30522)\n",
    "print(\"Model loaded & embeddings computed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Similarity Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:37:33.767456Z",
     "iopub.status.busy": "2025-12-24T09:37:33.767111Z",
     "iopub.status.idle": "2025-12-24T09:37:33.784484Z",
     "shell.execute_reply": "2025-12-24T09:37:33.783838Z",
     "shell.execute_reply.started": "2025-12-24T09:37:33.767434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_sub_matrix(word_list, engine):\n",
    "    \"\"\"\n",
    "    Re-computes embeddings for just the small list of words to find\n",
    "    connections between them.\n",
    "    \"\"\"\n",
    "    inputs = engine.tokenizer(word_list, return_tensors=\"pt\", padding=True, truncation=True).to(engine.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = engine.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "    return torch.mm(embeddings, embeddings.t()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:39:28.605378Z",
     "iopub.status.busy": "2025-12-24T09:39:28.604714Z",
     "iopub.status.idle": "2025-12-24T09:39:28.615167Z",
     "shell.execute_reply": "2025-12-24T09:39:28.614460Z",
     "shell.execute_reply.started": "2025-12-24T09:39:28.605346Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_network(seed_word, top_n, threshold):\n",
    "    try:\n",
    "        # Get Similar Words\n",
    "        similar_results = bert_model.get_similar_words(seed_word, top_n=top_n)\n",
    "        print(f\"Displaying top {top_n} words similar to '{seed_word}'\")\n",
    "        \n",
    "        # Prepare Data for Graph\n",
    "        found_words = [seed_word] + [item[0] for item in similar_results]\n",
    "        sim_matrix = get_sub_matrix(found_words, bert_model)\n",
    "\n",
    "        G = nx.Graph()\n",
    "        for w in found_words:\n",
    "            G.add_node(w)\n",
    "            \n",
    "        rows, cols = sim_matrix.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(i + 1, cols):\n",
    "                score = sim_matrix[i][j]\n",
    "                if score > threshold:\n",
    "                    G.add_edge(found_words[i], found_words[j], weight=score)\n",
    "\n",
    "        # NetworkX Layout\n",
    "        pos = nx.spring_layout(G, seed=42, k=0.5)\n",
    "\n",
    "        # Plotly Traces\n",
    "        edge_x, edge_y = [], []\n",
    "        for edge in G.edges():\n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_x.extend([x0, x1, None])\n",
    "            edge_y.extend([y0, y1, None])\n",
    "\n",
    "        edge_trace = go.Scatter(\n",
    "            x=edge_x, y=edge_y,\n",
    "            line=dict(width=0.5, color='#888'),\n",
    "            hoverinfo='none',\n",
    "            mode='lines')\n",
    "\n",
    "        node_x, node_y = [], []\n",
    "        node_text = []\n",
    "        node_adjacencies = []\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            x, y = pos[node]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "            node_text.append(node)\n",
    "            node_adjacencies.append(len(G.adj[node]))\n",
    "\n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x, y=node_y,\n",
    "            mode='markers+text',\n",
    "            text=node_text,\n",
    "            textposition=\"top center\",\n",
    "            hoverinfo='text',\n",
    "            marker=dict(showscale=True, colorscale='Plasma', reversescale=True, color=node_adjacencies,\n",
    "                        size=15, colorbar=dict(thickness=15, title=dict(text='Connections', side='right'),\n",
    "                                               xanchor='left')))\n",
    "\n",
    "        fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                        layout=go.Layout(\n",
    "                            title=f\"Network for '{seed_word}' (Similarity: {threshold})\",\n",
    "                            showlegend=False, hovermode='closest',\n",
    "                            margin=dict(b=20,l=5,r=5,t=40),\n",
    "                            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
    "        fig.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:39:29.479409Z",
     "iopub.status.busy": "2025-12-24T09:39:29.478852Z",
     "iopub.status.idle": "2025-12-24T09:39:31.720823Z",
     "shell.execute_reply": "2025-12-24T09:39:31.720245Z",
     "shell.execute_reply.started": "2025-12-24T09:39:29.479379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950c6aaeca32493cabbcc7f3634191c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='science', description='Search Term:'), IntSlider(value=30, description='Number of Wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ded200789d4061afb37fd1c2e1042a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Widgets\n",
    "seed_input = widgets.Text(value='science', description='Search Term:')\n",
    "top_n_slider = widgets.IntSlider(value=30, min=10, max=100, step=5, description='Number of Words:')\n",
    "threshold_slider = widgets.FloatSlider(value=0.9, min=0.5, max=0.99, step=0.01, description='Connection Threshold:')\n",
    "\n",
    "# Use interact to make it reactive\n",
    "ui = widgets.VBox([seed_input, top_n_slider, threshold_slider])\n",
    "out = widgets.interactive_output(visualize_network, {'seed_word': seed_input, 'top_n': top_n_slider, 'threshold': threshold_slider})\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "generativeModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
